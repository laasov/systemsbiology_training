---
title: "TMED917 2021 Set 1"
author: "Lassi Virtanen"
date: "04/2021"
output: pdf_document
---

## Task 1 - Mathematical modeling

## Task 2 - Modeling the spread of a viral infection

### Item a

```{r Dependencies, echo = F}
library(tidyverse)
library(viridis)
library(patchwork)
```

```{r}
# Parameterize path to tsv and read the data
data.path <- "~/Documents/intro_to_systems_biology/Exercise Set 1-20210428/thl-covid.tsv"
thl.data <- read_tsv(data.path, locale = locale(encoding = "UTF-8"))

# Pick the number of days
total.weeks <- 1:nrow(thl.data)

# Compute row sums
weekly.cases <- rowSums(thl.data[,2:ncol(thl.data)])

# Plot the row sums
p1 <- tibble(total.weeks, weekly.cases) %>%
        ggplot(aes(x = total.weeks, y = weekly.cases, fill = weekly.cases)) + 
        geom_bar(stat = "identity") +
        scale_fill_viridis_c() +
        scale_x_continuous(breaks = 1:length(thl.data$X1), labels = thl.data$X1) +
        theme(axis.text.x = element_text(angle = 90, size = 5)) +
        labs(fill = "Case count \n # people") +
        labs(title = "Progression of Covid-19 in Finland",
           x = "weeks from the initial measurements",
           y = "number of cases")

p1
```

```{r}
# Cumulate cases
cum.cases <- cumsum(weekly.cases)

# Plot cumulative row sums
p2 <- tibble(total.weeks, cum.cases) %>%
        ggplot(aes(x = total.weeks, cumsum(weekly.cases), fill = weekly.cases)) + 
        geom_bar(stat = "identity") +
        scale_fill_viridis_c() +
        scale_x_continuous(breaks = 1:length(thl.data$X1), labels = thl.data$X1) +
        theme(axis.text.x = element_text(angle = 90, size = 5)) +
        labs(fill = "Weekly cases \n # people") +
        labs(title = "Cumulative distribution of Covid-19 cases in Finland, colored by weekly count",
           x = "weeks from the initial measurements",
           y = "number of cases")

p2
```

### Item b

```{r Quantitative model of the exponential spread of Covid-19}
# Functionalize the formula
infected <- function(x) {

  B = 1.598 
  C = 0.836

  return(B * exp(C * x))
}
```

```{r Computations and modelling of the spread}
sprintf("At day 5, there would be %.3f cases", infected(5/7))
```

```{r Similar calculation for t = 2 months}
weeks.in.two.months <- 4 * 2

sprintf("At t = 4 weeks, there would be %.3f cases", infected(weeks.in.two.months))
```

```{r Predicting the time required to infect the entire world}
# Compute the number of weeks

B = 1.598 
C = 0.836

weeks.to.mayhem <- log(7.8e9 / B) / C

sprintf("It would require %.3f weeks to spread through the whole Earth", weeks.to.mayhem)
```

### Item c

```{r A dynamical system}
# Aux function for Runge-Kutta method
source('~/Documents/intro_to_systems_biology/Exercise Set 1-20210428/rk4.R')

# Set params
population <- 5.5e6
beta <- 2.430e-7
delta_inv <- 2 # weeks

system.of.eqns <- function(t, X) {

  "
  ---------------------------------------------------------------
  Modeling a dynamical system as follows

  s'(t) = -b*s(t)*i(t)
  i'(t) = b*s(t)*i(t) - d*i(t)
  r'(t) = d*i(t)

  where b, d = beta, delta in SIR model
  ---------------------------------------------------------------
  
  params:
    X: a list containing:
      1. the number of suspectible individuals
      2. the number of initially infected people
      3. the number of initially recovered people

  returns:
    derivatives (w.r.t. t) of SIR equations at time point t

  "

  s <- X[1]
  i <- X[2]
  r <- X[3]

  ds <- -beta*s*i
  di <- beta*s*i -delta_inv^(-1)*i
  dr <- delta_inv^(-1)*i

  return(c(ds, di, dr))
}

# Time period for which to run the simulation (pick from THL data)
t_scale <- total.weeks

# Number of people infected at week 0
initial.infected <- beta * population

# Vectorize the S, I, R model params
model.params <- c(population, initial.infected, 0) # initially 0 recovered

# Time scale + integration
rk_out <- rk4(system.of.eqns, t_scale, model.params)

# Select the model predictions
pred <- data.frame(t(rk_out$X))

# Convert to tibble
pred <- tibble(pred) %>% rename("S" = X1, "I" = X2, "R" = X3)
pred$time <- t_scale
pred$expo <- sapply(t_scale, infected)

# Plot
ggplot(pred, aes(x = time)) +
  geom_line(aes(y = S, color = "S"), linetype = "dotted") +
  geom_line(aes(y = I, color = "I"), linetype = "dotdash") + 
  geom_line(aes(y = R, color = "R"), linetype = "twodash") +
  geom_line(aes(y = expo, color = "exp"), linetype = "longdash") +
  labs(title = "Dynamical SIR system prediction for Covid-19 spread in Finland + exp growth",
           x = "weeks from the initial measurements",
           y = "number of individuals") +
  ylim(0, population)

```

### Item d

according to the SIR-model, the pandemic would peak at $t_{max}$ s.t. $i(t_{max})\approx 1.4\cdot10^6$. The number of people who would need treatment would of course be a function of time, but if we assume that $.5\%$ of people infected at time $t$ would need treatment, in simulatneous need would ttherefore be $.5\%\cdot i(t)$. In reality these numbered were not reached due to restrictions and relatively effective policy-making. The model is somewhat naive and does not take into consideration many Covid-19 specific cases, \textit{e.g.}, the lockdowns and actual human behaviour.

## Task 3 - Simulating Monty Hall problem

```{r}

simulate.mhall <- function(num_iter) {

  # Self explanatory
  n_doors <- 3
  
  # Win count by changed strategy and initial strategy
  w.c <- 0
  w.nc <- 0

  for (i in 1:num_iter) {

    # Rng the prize door and guess good. Not mutex so replace = T
    prize <- sample(1:n_doors, 1, replace = T)
    guess <- sample(1:n_doors, 1, replace = T)

    # Opened door and a possible new guess
    host.opens <- setdiff(1:n_doors, c(prize, guess)) %>% sample(1)
    new.guess <- setdiff(1:n_doors, c(guess, host.opens)) %>%  sample(1)

    if (prize == guess) {
      w.nc <- w.nc + 1
    }
    
    if (prize == new.guess) {
      w.c <- w.c + 1
    }
  }
  
  c.freq <- w.c / (w.c + w.nc)
  nc.freq <- w.nc / (w.c + w.nc)

  sprintf("Total iter: %5.d  |  Wins by changed strategy: %.2f  |  Wins by initial strategy: %.2f",
          num_iter, c.freq, nc.freq) 
}

```

### Item b

```{r}
# Simulate Monty Hall problem
iterations <- c(3, 5, 8, 1e2, 1e4)

# For nice results:
mhall.simus <- sapply(iterations, simulate.mhall)
mhall.simus
```

We should begin to see convergence towards the correct probabilities fairly quickly, but this one did not do it. Usually when simulating the Monty Hall problem (if I remember correctly, it's been a few moments since I did the last time...), a few thousand iterations should be enough for a convergence of $\varepsilon \leq 1\%$. Well, maybe it is the random take we had now at $n=10000$ that just does not tell the story. The probabilities of winning the Monty Hall problem are $P(S)=\frac{2}{3}$ and $P(N)=\frac{2}{3}$ where $S = \:''switch''$ and $N = \:''don't \: switch''$. The statement can be justified with Bayesian modeling as follows:

For any door $d \in \{1,2,3\}$, the probability of it being the winning door is $P(\mathrm{win}=d)=\frac{1}{3}$.

Two cases follow. Consider the winning door $d_w$. This car would never be opened, so we can focus on two remaining doors. The likelihoods of the remaining doors, say, $d_a$ and $d_b$ being opened are therefore

$$P(\mathrm{open} = d_a \: | \: \mathrm{door} = d_b) = \frac{1}{2}$$

$$P(\mathrm{open} = d_b \: | \: \mathrm{door} = d_w) = 1$$

It immediately follows that

$$P(\mathrm{door} = d_a \: | \: \mathrm{open} = d_b)=\frac{\frac{1}{2}\cdot\frac{1}{3}}{P(d_b)=\frac{1}{2}}=\frac{1}{3}$$

And

$$P(\mathrm{door} = d_a \: | \: \mathrm{open} = d_b)=\frac{1\cdot\frac{1}{3}}{P(d_b)=\frac{1}{2}}=\frac{2}{3}$$

Where $P(d_b)$ is simply the sum $\frac{1}{2}\cdot\frac{1}{3}+\cdot\frac{1}{3}$ from the events following from

$$P(d_b)=P(\mathrm{door} = d_a)\cdot P(\mathrm{open} = d_b \: | \: \mathrm{door} = d_a) + P(\mathrm{door} = d_w)\cdot P(\mathrm{open} = d_b \: | \: \mathrm{door} = d_w)$$